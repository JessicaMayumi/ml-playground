{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75ba4f4",
   "metadata": {},
   "source": [
    "## üìÖ Dia 2 ‚Äì Introdu√ß√£o ao PyTorch + MNIST\n",
    "\n",
    "### üéØ Objetivo:\n",
    "Aprender a usar PyTorch para construir uma rede neural simples com base no dataset MNIST.\n",
    "\n",
    "### üìö Teoria:\n",
    "\n",
    "#### üß± Componentes do PyTorch\n",
    "- **`torch.nn.Module`**: classe base para modelos.\n",
    "- **`nn.Linear`**: camadas densas.\n",
    "- **`F.relu`, `F.softmax`, etc.**: fun√ß√µes de ativa√ß√£o.\n",
    "- **`loss_fn`**: fun√ß√£o de perda (ex: `CrossEntropyLoss`).\n",
    "- **`optimizer`**: atualiza√ß√£o dos pesos (ex: `SGD`, `Adam`).\n",
    "\n",
    "#### üì¶ Dataset MNIST\n",
    "- Imagens 28x28 pixels em tons de cinza.\n",
    "- D√≠gitos de 0 a 9.\n",
    "- Conjunto cl√°ssico para classifica√ß√£o.\n",
    "\n",
    "#### ‚öôÔ∏è Otimizadores\n",
    "- **SGD (Stochastic Gradient Descent)**: simples e direto.\n",
    "- **Adam**: adaptativo, geralmente mais r√°pido e eficaz.\n",
    "\n",
    "#### üìâ Fun√ß√µes de perda e m√©tricas\n",
    "- **Loss**: `sparse_categorical_crossentropy` (para classifica√ß√µes inteiras).\n",
    "- **M√©tricas**: `accuracy`.\n",
    "\n",
    "### üõ† Pr√°tica:\n",
    "- Criar um modelo para MNIST com 1 camada oculta\n",
    "- Treinar e avaliar com accuracy, loss\n",
    "- Plotar gr√°fico de acur√°cia e perda por √©poca\n",
    "- Modificar o modelo:\n",
    "- Mais camadas\n",
    "- Fun√ß√£o de ativa√ß√£o diferente\n",
    "- Alterar epochs, batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca06d98d",
   "metadata": {},
   "source": [
    "\n",
    "# Pytorch\n",
    "Uma biblioteca de ML para Deep Learning.\n",
    "\n",
    "Tensores: vari√°veis indexadas(arrays) multidimensionais usadas como base para todas as opera√ß√µes avan√ßadas.\n",
    "\n",
    "5 tipos de tensores:\n",
    "- HalfTensor: 16-bit float\n",
    "- FloatTensor: 32-bit float\n",
    "- DoubleTensor: 64-bit float\n",
    "- IntTensor: 32-bit int\n",
    "- LongTensor: 64-bit int\n",
    "\n",
    "0D: um √∫nico valor real -> esc = torch.tensor(7)\n",
    "\n",
    "1D: vetor -> notas = torch.tensor([8.5, 9.0, 7.0])\n",
    "\n",
    "2D: matriz -> matriz = torch.tensor([[1, 2], [3, 4]]) ou t = torch.rand(2, 3) # Cria um tensor 2x3 com n√∫meros aleat√≥rios entre 0 e 1\n",
    "\n",
    "3D: Imagens -> imagemPretoBraco = torch.rand(1, 28, 28) # 1 canal (preto e branco), 28x28 pixels\n",
    "            -> imaemRGB = torch.rand(32, 3, 224, 224)  # 32 imagens, RGB, 224x224\n",
    "\n",
    "OBS: o padr√£o √© FloatTensor, e para alterar utiliza-se torch.set_default_tensor_type(t)\n",
    "\n",
    "Refer√™ncia: \n",
    "- https://www.insightlab.ufc.br/tutorial-pytorch-um-guia-rapido-para-voce-entender-agora-os-fundamentos-do-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54104b86",
   "metadata": {},
   "source": [
    "##  Importando as bibliotecas b√°sicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8822b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d81b1c",
   "metadata": {},
   "source": [
    "###  Definir o conjunto de dados\n",
    "Nesse caso ser√° utilizado o mesmo exemplo pr√°tico do dia anterior (XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5bdaf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de entrada (XOR)\n",
    "entradas = torch.tensor([[0, 0],\n",
    "                         [0, 1],\n",
    "                         [1, 0],\n",
    "                         [1, 1]], dtype=torch.float32)\n",
    "\n",
    "# Sa√≠das desejadas\n",
    "saidas = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b6638",
   "metadata": {},
   "source": [
    "### Criando o modelo: subclasse de nn.Module\n",
    "√â a classe base de todos os modelos de redes neurais em PyTorch. Sempre que criado uma rede neural personalizada, √© necess√°rio herdar essa classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825da9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedeXOR(nn.Module): #herdando o nn.Module\n",
    "    def __init__(self):\n",
    "        super(RedeXOR, self).__init__()\n",
    "        self.oculta = nn.Linear(2, 2)   # Camada oculta com 2 neur√¥nios\n",
    "        self.saida = nn.Linear(2, 1)    # Camada de sa√≠da\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.oculta(x))  # Ativa√ß√£o tanh na oculta\n",
    "        x = torch.sigmoid(self.saida(x))  # Sigmoid na sa√≠da\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8eaf38",
   "metadata": {},
   "source": [
    "### Instanciando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6b0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = RedeXOR()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a891edf",
   "metadata": {},
   "source": [
    "### Definindo a Fun√ß√£o de Perda e Otimizador\n",
    "Componentes respons√°veis por atualizar os pesos da rede, ajudando a minimizar a fun√ß√£o de perda.\n",
    "\n",
    "### Otimizadores mais utilizados:\n",
    "- **SGD (Stochastic Gradient Descent):** O mais simples, atualiza pesos usando uma fra√ß√£o aleat√≥ria dos dados.\n",
    "- **RMSprop:** Ajusta o tamanho do passo com base na m√©dia dos gradientes anteriores. Muito bom para RNNs.\n",
    "- **Momentum:** Acelera o SGD acumulando velocidade (como uma bola rolando ladeira abaixo).\n",
    "- **Adam:** O mais usado atualmente, combina vantagens do SGD com Momentos e adapta a taxa de aprendizado automaticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c78568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio = nn.MSELoss()  # Fun√ß√£o de perda: erro quadr√°tico m√©dio\n",
    "otimizador = optim.SGD(modelo.parameters(), lr=0.1)  # Gradiente descendente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c01936",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d9f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoca in range(10000):\n",
    "    saidas_preditas = modelo(entradas) # Forward\n",
    "    perda = criterio(saidas_preditas, saidas) # Calcula erro\n",
    "\n",
    "    otimizador.zero_grad() # Zera gradientes anteriores\n",
    "    perda.backward() # Backpropagation: calcula novos gradientes\n",
    "    otimizador.step() # Atualiza os pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb9797e",
   "metadata": {},
   "source": [
    "### Resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "595cd8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sa√≠das ap√≥s o treinamento:\n",
      "tensor([[0.0308],\n",
      "        [0.9603],\n",
      "        [0.9609],\n",
      "        [0.0272]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Sa√≠das ap√≥s o treinamento:\")\n",
    "print(modelo(entradas).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace016d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
